---
title: "Preprocesamiento_Visualizacion_ASupervisado"
author: "Emilia Coleto y Manuel García"
date: "28/12/2021"
output:
  html_document: default
  pdf_document: default
---

```{r}
#Instalación y uso de tidyverse. Se usará el paquete dplyr para el preprocesamiento y ggplot2 para la visualización
install.packages("tidyverse")
library(tidyverse)

#Visualización del dataframe original heart.csv
heart <- read.csv('heart.csv')
View(heart)

colnames(heart)
dim(heart)

names(heart$Age)

```

```{r Preprocesamiento 1: Valores perdidos y Filas duplicadas}
#Buscamos si hay algún valor que sea un espacio en blanco, NaN o haya alguna observación duplicada.

heart <- read.table("heart.csv", na.strings="", header=TRUE, sep=",", dec=".")
#Se va a interpretar todos aquellos huecos en blanco como NA (Not Available).
str(heart)

#POdemos comprobar de dos formas que no contiene NA. 
#1º Haciendo tablas de frecuencia para ver que valores toman las observaciones en cada atributo

attach(heart)#attacha "engancha" el contenido del dataframe al entorno donde R busca los nombres de las variables

table(Cholesterol)
table(Age)
table(Sex)
table(ChestPainType)
table(RestingBP)
table(FastingBS)
table(RestingECG)
table(MaxHR)
table(ExerciseAngina)
table(Oldpeak)
table(ST_Slope)
table(HeartDisease)

#2º Detectando con la funcion complete.cases si hay algun NA (Devolveria false en aquella observación que tuviera un NA). Todos son TRUE
complete.cases(heart)


#Por otro lado queremos saber si hay observaciones 
duplicated(heart)#Todas las observaciones son únicas, ya que devuelven FALSE. Si hubiera al menos dos duplicadas, aparecerían como TRUE


#Concluimos que no hay ni espacios en blanco ni NA en nuestro Dataframe inicial.

```

```{r Preprocesamiento 2: Detección y eliminación de outliers}
#Para ello, haremos uso del comando boxplot (Diagrama de cajas y bigotes para encontrar los outliers y el filtrado del paquete dplyr para eliminarlos del dataset y quedarnos con uno más limpio.
#Nos fijaremos en los atributos con valores continuos.
 
str(heart) #Contenido de heart.csv
head(heart)

#Buscaremos outliers en los atributos Age, RestingBP, Cholesterol, MaxHR y OldPeak

boxplot(heart$Age, horizontal = TRUE)
#Detectamos que con la variable edad no se produce ningún outlier, por lo que continuaremos con el resto de atributos, donde si encontraremos algunos.

```


```{r Preprocesamiento 2: Detección y eliminación de outliers: Atributo RestingBP}
RestingBP <- heart$RestingBP

boxplot(RestingBP, horizontal = TRUE) #Vemos que hay outliers
boxplot.stats(RestingBP)#Hay outliers por debajo de 92 y por encima de 170
heart_Sin_Out_RestingBP <- RestingBP[RestingBP>92 & RestingBP<170] #Nos quedamos con el subconjunto dejando fuera a los outliers
boxplot(heart_Sin_Out_RestingBP, horizontal = TRUE) #comprobamos que no hay outliers
boxplot.stats(heart_Sin_Out_RestingBP)

#FIltrado del dataframe mediante paquete dplyr para eliminar outliers de RestingBP
heart1 <- filter(heart, RestingBP > 92 & RestingBP<170) #Filtramos nuestro dataframe "heart" para obtener uno nuevo sin los outliers.

str(heart1)#Nuevo dataframe "heart1" con 875 observaciones
head(heart1)

#Repetiriamos el proceso para los restantes atributos

```

```{r Preprocesamiento 2: Detección y eliminación de outliers: Atributo Cholesterol}

Cholesterol <- heart1$Cholesterol

boxplot(Cholesterol, horizontal=TRUE)
boxplot.stats(Cholesterol)
heart1_Sin_Out_Cholesterol <- Cholesterol[Cholesterol >0 & Cholesterol < 404]
boxplot(heart1_Sin_Out_Cholesterol, horizontal=TRUE)
boxplot.stats(heart1_Sin_Out_Cholesterol) #En este caso en partircular, vemos que al hacer las modificaciones por haber tanto outliers, vuelve a haber outliers quedandonos con un subconjunto. Volveremos a repetir este paso hasta que nos quedemos sin outliers.

heart2_Sin_out_Cholesterol2 <- heart1_Sin_Out_Cholesterol[heart1_Sin_Out_Cholesterol > 110 & heart1_Sin_Out_Cholesterol< 369]
boxplot(heart2_Sin_out_Cholesterol2, horizontal=TRUE)

#FIltrado del dataframe mediante paquete dplyr para eliminar outliers de CHholesterol
heart2 <- filter(heart1, Cholesterol > 110 & Cholesterol < 369)

str(heart2)#Nuevo dataframe "heart2" con 690 observaciones
head(heart2)


```

```{r Preprocesamiento 2: Detección y eliminación de outliers: Atributo MaxHR}

MaxHR <- heart2$MaxHR
boxplot(MaxHR, horizontal=TRUE)
boxplot.stats(MaxHR)#No es necesario el filtrado puesto que el actual dataframe(heart2) no contiene outliers para ese atributo

str(heart2)

```

```{r Preprocesamiento 2: Detección y eliminación de outliers: Atributo OldPeak. FIN de Preprocesamiento 1}

OldPeak <- heart2$Oldpeak
boxplot(OldPeak, horizontal=TRUE)
boxplot.stats(OldPeak)
heart2_Sin_out_OldPeak <- OldPeak[OldPeak < 3.6]
boxplot(heart2_Sin_out_OldPeak, horizontal=TRUE)
boxplot.stats(heart2_Sin_out_OldPeak)

#Filtrado del dataframe mediante paquete dplyr para eliminar outliers de Oldpeak
heart3<- filter(heart2, OldPeak < 3.6)

##Dataset FINAL  sin outliers
str(heart3) #Dataframe final con 674 observaciones
View(heart3)

#Se puede comprobar que no hay  outliers en el dataframe "heart3" con los siguientes comandos boxplot
boxplot(heart3$RestingBP, horizontal = TRUE)
boxplot(heart3$Cholesterol, horizontal = TRUE)
boxplot(heart3$MaxHR, horizontal = TRUE)
boxplot(heart3$Oldpeak, horizontal = TRUE)

summary(heart3) #Resumen del dataframe "heart3"

```

Preparamos la visualización de los datos del dataset. La visualización se realiza con la librería "ggplot2" y se divide el dataset en pacientes con ataque al corazón y pacientes sin ataque al corazón.
```{r}
install.packages('ggplot2')
library(ggplot2)

heartDisease <- subset(heart3, HeartDisease == 1) 
heartDisease #Pacientes con ataque al corazón
notHeartDisease <- subset(heart3, HeartDisease == 0)
notHeartDisease #Pacientes sin ataque al corazón

```
## Diagramas de dispersión
Se pretende comprobar si las propiedades de cada elemento del dataset están relacionadas entre sí en pacientes con ataque al corazón. Por ello, se utiliza un diagrama de dispersión.

```{r}
ggplot(heartDisease, aes(x=Age, y=Cholesterol)) +
  geom_point()
# No estan fuertemente relacionadas la edad con el colesterol para tener un ataque al corazón
```
Como podemos observar en el gráfico, las variables edad y colesterol no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$Age, heartDisease$Cholesterol)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas no están relacionadas.

```{r}
ggplot(heartDisease, aes(x=Age, y=RestingBP)) +
  geom_point()
#No estan relacionadas la edad con la presión sanguínea para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables edad y la presión sanguínea no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$Age, heartDisease$RestingBP)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas tienen una correlación baja.

```{r}
ggplot(heartDisease, aes(x=Age, y=MaxHR)) +
  geom_point()
#No estan relacionadas la edad con la presión sanguínea para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables edad y ritmo cardíaco no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$Age, heartDisease$MaxHR)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas están muy poco relacionadas.

```{r}
ggplot(heartDisease, aes(x=Age, y=Oldpeak)) +
  geom_point()
#No estan relacionadas la edad con la depresión del segmento ST para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables edad y la depresión del segmento ST no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$Age, heartDisease$Oldpeak)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas no están relacionadas.

```{r}
ggplot(heartDisease, aes(x=Cholesterol, y=RestingBP)) +
  geom_point()
#No estan relacionadas el colesterol con la presión sanguínea para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables colesterol y presión sanguínea no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$Cholesterol, heartDisease$RestingBP)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas no están relacionadas.

```{r}
ggplot(heartDisease, aes(x=Cholesterol, y=MaxHR)) +
  geom_point()
#No estan relacionadas la edad con la presión sanguínea para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables colesterol y ritmo cardíaco no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$Cholesterol, heartDisease$MaxHR)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas no están relacionadas.

```{r}
ggplot(heartDisease, aes(x=Cholesterol, y=Oldpeak)) +
  geom_point()
#No estan relacionadas la edad con la depresión del segmento ST para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables colesterol y depresión del segmento ST no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$Cholesterol, heartDisease$Oldpeak)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas no están relacionadas.

```{r}
ggplot(heartDisease, aes(x=RestingBP, y=MaxHR)) +
  geom_point()
#No estan relacionadas la edad con la presión sanguínea para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables presión sanguínea y ritmo cardíaco no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$RestingBP, heartDisease$MaxHR)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas están relacionadas a muy bajo nivel.

```{r}
ggplot(heartDisease, aes(x=RestingBP, y=Oldpeak)) +
  geom_point()
#No estan relacionadas la edad con la depresión del segmento ST para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables presión sanguínea y depresión del segmento ST no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$RestingBP, heartDisease$Oldpeak)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas están relacionadas a muy bajo nivel.

```{r}
ggplot(heartDisease, aes(x=MaxHR, y=Oldpeak)) +
  geom_point()
#No estan relacionadas la edad con la depresión del segmento ST para tener un ataque al corazon
```
Como podemos observar en el gráfico, las variables máximo ritmo cardíaco y depresión del segmento ST no están relacionadas, por tanto no se puede sacar ninguna conclusión entre ellas para predecir ataques al corazón.
```{r}
cor(heartDisease$MaxHR, heartDisease$Oldpeak)
```
Obteniendo el valor de la correlación entre estas variables, podemos afirmar que estas están relacionadas a muy bajo nivel.

## Diagramas de barras
Con la visualización de estas gráficas, se pretende analizar cómo se agrupan por categorías entre las dos variables comparadas.

```{r Composición de ataques al corazón según el tipo de dolor de pecho}
subsetASY0 <- subset(notHeartDisease, ChestPainType == "ASY")
subsetATA0 <- subset(notHeartDisease, ChestPainType == "ATA")
subsetNAP0 <- subset(notHeartDisease, ChestPainType == "NAP")
subsetTA0 <- subset(notHeartDisease, ChestPainType == "TA")

subsetASY1 <- subset(heartDisease, ChestPainType == "ASY")
subsetATA1 <- subset(heartDisease, ChestPainType == "ATA")
subsetNAP1 <- subset(heartDisease, ChestPainType == "NAP")
subsetTA1 <- subset(heartDisease, ChestPainType == "TA")

data <- data.frame(
  Dolor = c("ASY", "ATA", "NAP", "TA", "ASY", "ATA", "NAP", "TA"),
  Ataque = c("no","no", "no","no","si","si" ,"si","si"),
  Individuos = c(nrow(subsetASY0), nrow(subsetATA0), nrow(subsetNAP0), nrow(subsetTA0), nrow(subsetASY1), nrow(subsetATA1), nrow(subsetNAP1), nrow(subsetTA1))
)

ggplot(data, mapping=(aes(x=Ataque, y=Individuos, fill=Dolor))) +
  ggtitle("Composición de ataques al corazón según el tipo de dolor de pecho") +
  geom_bar(stat="identity", position = 'dodge') +
  geom_text(mapping=(aes(label=Individuos)), position = position_dodge(0.9))
```
Como se observa en la gráfica el tipo de dolor entre pacientes con ataque al corazón y no, varía bastante. Siendo el tipo "ASY" el predominante en pacientes con ataque al corazón.

```{r Composición de ataques al corazón según el sexo}
subsetF0 <- subset(notHeartDisease, Sex == "F")
subsetM0 <- subset(notHeartDisease, Sex == "M")

subsetF1 <- subset(heartDisease, Sex == "F")
subsetM1 <- subset(heartDisease, Sex == "M")

data <- data.frame(
  Sexo = c("F","M","F","M"),
  Ataque = c("no","no","si","si"),
  Individuos = c(nrow(subsetF0),nrow(subsetM0),nrow(subsetF1),nrow(subsetM1))
)

ggplot(data, mapping=(aes(x=Ataque, y=Individuos, fill=Sexo))) +
  ggtitle("Composición de ataques al corazón según el sexo") +
  geom_bar(stat = 'identity', position = 'dodge') +
  geom_text(mapping=(aes(label=Individuos)), position = position_dodge(0.9))
```
Como se observa en la gráfica el se han obtenido más datos de hombres que de mujeres. Siendo mucho más usual el ataque al corazón en hombres que en mujeres.

```{r Composición de ataques al corazón según la glucemia en ayunas}
subset00 <- subset(notHeartDisease, FastingBS == "0")
subset10 <- subset(notHeartDisease, FastingBS == "1")

subset01 <- subset(heartDisease, FastingBS == "0")
subset11 <- subset(heartDisease, FastingBS == "1")

data <- data.frame(
  Glucemia = c("no", "si","no", "si"),
  Ataque = c("no","no","si","si"),
  Individuos = c(nrow(subset00), nrow(subset10), nrow(subset01), nrow(subset11))
)

ggplot(data, mapping=(aes(x=Ataque, y=Individuos, fill=Glucemia))) +
  ggtitle("Composición de ataques al corazón según la glucemia en ayunas") +
  geom_bar(stat="identity", position = 'dodge') +
  geom_text(mapping=(aes(label=Individuos)), position = position_dodge(0.9))
```
Como podemos observar, se tienen más datos de pacientes sin hiperglucemia que con ella. Y como se aprecia en los individuos con ataque al corazón, tener hiperglucemia no indica que haya más posibilidades de infarto.

```{r Composición de ataques al corazón según resultados electrocardiográficos en reposo}
subsetLVH0 <- subset(notHeartDisease, RestingECG == "LVH")
subsetNormal0 <- subset(notHeartDisease, RestingECG == "Normal")
subsetST0 <- subset(notHeartDisease, RestingECG == "ST")

subsetLVH1 <- subset(heartDisease, RestingECG == "LVH")
subsetNormal1 <- subset(heartDisease, RestingECG == "Normal")
subsetST1 <- subset(heartDisease, RestingECG == "ST")

data <- data.frame(
  Resultados = c("LVH", "Normal", "ST", "LVH", "Normal", "ST"),
  Ataque = c("no","no", "no","si","si","si"),
  Individuos = c(nrow(subsetLVH0), nrow(subsetNormal0), nrow(subsetST0), nrow(subsetLVH1), nrow(subsetNormal1), nrow(subsetST1))
)

ggplot(data, mapping=(aes(x=Ataque, y=Individuos, fill=Resultados))) +
  ggtitle("Composición de ataques al corazón según resultados \n electrocardiográficos en reposo") +
  geom_bar(stat="identity", position = 'dodge') +
  geom_text(mapping=(aes(label=Individuos)), position = position_dodge(0.9))
```
Como se observa en la gráfica, ningún tipo de resultado en el electrocardiograma puede predecir si el paciente va a sufrir un ataque al corazón o no.

```{r Composición de ataques al corazón según angina inducida por el ejercicio}
subsetN0 <- subset(notHeartDisease, ExerciseAngina == "N")
subsetY0 <- subset(notHeartDisease, ExerciseAngina == "Y")

subsetN1 <- subset(heartDisease, ExerciseAngina == "N")
subsetY1 <- subset(heartDisease, ExerciseAngina == "Y")

data <- data.frame(
  Angina = c("no", "sí", "no", "sí"),
  Ataque = c("no","no","si","si"),
  Individuos = c(nrow(subsetN0), nrow(subsetY0), nrow(subsetN1), nrow(subsetY1))
)

ggplot(data, mapping=(aes(x=Ataque, y=Individuos, fill=Angina))) +
  ggtitle("Composición de ataques al corazón según angina inducida por el ejercicio") +
  geom_bar(stat="identity", position = 'dodge') +
  geom_text(mapping=(aes(label=Individuos)), position = position_dodge(0.9))
```
En la gráfica podemos ver la disparidad entre la relación de tener ataque al corazón con tener angina. Se puede afirmar, que las personas con angina son más propensas al ataque al corazón que las que no.

```{r Composición de ataques al corazón según la pendiente del segmento ST del ejercicio maximo}
subsetD0 <- subset(notHeartDisease, ST_Slope == "Down")
subsetF0 <- subset(notHeartDisease, ST_Slope == "Flat")
subsetU0 <- subset(notHeartDisease, ST_Slope == "Up")

subsetD1 <- subset(heartDisease, ST_Slope == "Down")
subsetF1 <- subset(heartDisease, ST_Slope == "Flat")
subsetU1 <- subset(heartDisease, ST_Slope == "Up")

data <- data.frame(
  Pendiente = c("Down", "Flat", "Up", "Down", "Flat", "Up"),
  Ataque = c("no","no","no","si","si","si"),
  Individuos = c(nrow(subsetD0), nrow(subsetF0), nrow(subsetU0), nrow(subsetD1), nrow(subsetF1), nrow(subsetU1))
)

ggplot(data, mapping=(aes(x=Ataque, y=Individuos, fill=Pendiente))) +
  ggtitle("Composición de ataques al corazón según la pendiente del \n segmento ST del ejercicio maximo") +
  geom_bar(stat="identity", position = 'dodge') +
  geom_text(mapping=(aes(label=Individuos)), position = position_dodge(0.9))
```
Podemos afirmar que las personas sin pendiente en el segmento ST, padecen más ataques al corazón que las de pendiente ascendente o descendente.

### Análisis supervisado: KNN
```{r Carga de librerías y obtención de datos}
library(tidyverse)
library(class)
library(gmodels)
library(caret)
data <- read.delim("heart3_ApSuperv.csv", sep = ",", head = TRUE)
```

```{r Transformación de datos: de cualitativos a cuantitativos}
transformData <- function(data = data) {
  for(i in 1:nrow(data)) {
    #Transformo sexo
    if(data[i,"Sex"]=="M"){
      data[i,"Sex"]<-0
    }else{
      data[i,"Sex"]<-1
    }
    #Transformo dolor de pecho "ASY", "ATA", "NAP", "TA"
    if(data[i,"ChestPainType"]=="ASY"){
      data[i,"ChestPainType"]<-0
    }else if(data[i,"ChestPainType"]=="ATA") {
      data[i,"ChestPainType"]<-1
    }else if(data[i,"ChestPainType"]=="NAP") {
      data[i,"ChestPainType"]<-2
    }else {
      data[i,"ChestPainType"]<-3
    }
    #Transformo resultados electrocardiográfico "LVH", "Normal", "ST"
    if(data[i,"RestingECG"]=="LVH"){
      data[i,"RestingECG"]<-0
    }else if(data[i,"RestingECG"]=="Normal") {
      data[i,"RestingECG"]<-1
    }else {
      data[i,"RestingECG"]<-2
    }
    #Transformo angina
    if(data[i,"ExerciseAngina"]=="N"){
      data[i,"ExerciseAngina"]<-0
    }else{
      data[i,"ExerciseAngina"]<-1
    }
    #Transformo pendiente del segmento ST "Down", "Flat", "Up"
    if(data[i,"ST_Slope"]=="Down"){
      data[i,"ST_Slope"]<-0
    }else if(data[i,"ST_Slope"]=="Flat") {
      data[i,"ST_Slope"]<-1
    }else {
      data[i,"ST_Slope"]<-2
    }
  }
  #Paso todos los datos a tipos numéricos
  data$Sex <- as.integer(data$Sex)
  data$ChestPainType <- as.integer(data$ChestPainType)
  data$RestingECG <- as.integer(data$RestingECG)
  data$ExerciseAngina <- as.integer(data$ExerciseAngina)
  data$ST_Slope <- as.integer(data$ST_Slope)
  return(data)
}
transformedData <- transformData(data)
transformedData
```

```{r KNN}
#Separo los datos de entrenamiento (75%) y test (25%)
train <- transformedData[1:(0.75*nrow(transformedData)),]
test <- transformedData[(0.75*nrow(transformedData)+1):674,]

#Guardo la columna a predecir
train_labels <- train$HeartDisease
test_labels <- test$HeartDisease

#Copio los datos para el knn
knn_train <- train
knn_test <- test

#Elimino id y columna a predecir
knn_train$HeartDisease <- NULL
knn_train$X <- NULL
knn_test$HeartDisease <- NULL
knn_test$X <- NULL

#Normalizo los datos de entrenamiento y test
normalize <- function(x){
  return ((x - min(x))/(max(x) - min(x)))
}
train_n <- as.data.frame(lapply(knn_train[1:11], normalize))
test_n <- as.data.frame(lapply(knn_test[1:11], normalize))

#KNN
set.seed(1)
pred <- knn(train = train_n, test = test_n, cl = train_labels, k = 22)

#Matriz de confusión
tab <- table(test_labels, pred)
tab

#Precisión
acc_knn <- sum(diag(tab)) / sum(tab)
print(acc_knn)
```
Tras ejecutar el algoritmo KNN, con este modelo (con k=22, ya que sqrt(505)~=22) obtenemos una precisión del 79.17% para acertar una predicción. Por tanto, en un  20.83% de las ocasiones fallaremos.

```{r Mejora del modelo}
set.seed(1)
range <- 1:round(0.2 * nrow(train_n))
acc_m <- rep(0, length(range))

for(k in range) {
  pred_m <- knn(train_n, test_n, train_labels, k = k)
  conf <- table(test_labels, pred_m)
  acc_m[k] <- sum(diag(conf)) / sum(conf)
}

# Grafica con las diferentes precisiones obtenidas
plot(range, acc_m, xlab = "k")

# Coge el k que devuelve la máxima precisión
which.max(acc_m)
acc_m[which.max(acc_m)]

pred_f <- knn(train_n, test_n, train_labels, k = 5)
tab_f <- table(test_labels, pred_f)
tab_f
```
Por tanto, situando el número de vecinos a 5 obtenemos la mayor precisión del modelo: 82,74%.

```{r Análisis a realizar: SUPERVISADO. Modelos predictivos de clasificación: Algoritmo ID3 y KNN. Método de Evaluación: Curva ROC}
```
##
```{r Instalación y carga de paquete caret y rattle}
#TODO: ALGUN ALGORITMO USANDO DEPENDENCIAS del paquete CARET (VER PRACTICA 5 y final de este archivo)
#TODO: ALGORITMO KNN. jodienda de tener que pasar valores discretos a numericos.

install.packages('caret')
library(caret)
library(dplyr) #Para manipular dataframes

install.packages("rattle")

library(rpart)
library(rattle)
library(RColorBrewer)

# Carga librería ROCR 
install.packages("ROCR")
library(ROCR)

#Carga libreria Class
library(class)
```

Lectura del heart3_ApSuperv.csv, el cual es el csv proveniente del dataframe final elaborado en el preprocesamiento. Este csv contiene una columna nueva ("X") generada al usar el write.csv.Podemos eliminar la columna haciendola NULL.
```{r}
asuper <- read.csv("heart3_ApSuperv.csv")
rownames(asuper)=asuper$X
asuper$X=NULL

dim(asuper)
str(asuper)


# Set random seed. Fijamos una semilla lo cual significa inicializar un generador de números pseudoaleatorios necesarios para los métodos de simulación 
set.seed(1)

```

Generaremos un modelo de árbol de decisión mediante el algoritmo CART con criterio de división Gini acorde a nuestro dataset preprocesado (asuper)..

#Interpretación
El árbol obtenido lo podemos interpretar (de arriba a abajo) de la siguiente manera:
-Fijándonos en el nodo que se encuentra más arriba (ST_Slope), tenemos que la mayoría de los datos clasifica como 0 con un 55% (NO HearDisease) antes que 1 con un 45% ( SI HeartDisease) y la separación que hace es respecto a la pendiente del segmento ST (ST_Slope) = UP

- Si ST_Slope = UP, el siguiente nodo(2) será el de ChestPainType = ATA,NAP,TA, en el que la mayoría de casos restantes(49%) clasifica como 0 (NO HEARTDISEASE) con un 87% y un 13% restante como 1 (SI HEARTDISEASE)

Por el contrario, si ST_Slope tiene otro valor distinto a UP, el siguiente nodo(3) será el de SEX = F, en el que la mayoría clasifica como 1 (SI HEARTDISEASE) con un 77% y un 23% restante con un 0 (NO HEARTDISEASE).

y así sucesivamente con los nodos inferiores.
```{r Generación de árbol de decisión, Algoritmo CART con criterio de división Gini}

tree <- rpart(HeartDisease~., asuper, method = "class")

# Plot del árbol
fancyRpartPlot(tree)

```

Calculamos la matriz de confusión para tener una primera aproximación de saber como clasifica este modelo elaborado por el algoritmo CART

```{r Predicción, matriz de confusión y accuracy del árbol de decisión. Algortimo CART }
# Predice los valores del conjunto de asuper a partir del árbol de decisión anteriormente generado.
pred <- predict(tree, asuper, type = "class")

# Construye la matriz de confusion
conf <- table(asuper$HeartDisease, pred)
conf #60 falsos positivos, 33 falsos negativos, 309 verdaderos negativos, 272 verdaderos positivos

# Calcula accuracy, la exactitud o el porcentaje de casos que el modelo ha acertado.
acc <- sum(diag(conf)) / sum(conf)
print(acc)
#Hemos tenido un accuracy del 0.8620178 ~ 86,2%

```

Pasamos a probar el algoritmo ID3, el cual se asemeja a CART ya que son árboles de decisión, pero lo diferencia de este último en que utiliza la ganancia de información como heurística. También mostramos la matriz de confusión.

```{r Modelo construido por el Algoritmo ID3 y su respectiva matriz de confusión}
# Cambia la llamada a rpart para utilizar como heurística la ganancia de información
tree_i <- rpart(HeartDisease ~ ., asuper, method = "class", 
                parms = list(split = "information"),control = rpart.control(cp=0.01))

fancyRpartPlot(tree_i) #Árbol de decisión generado mediante algoritmo ID3.

pred_i <- predict(tree_i, asuper, type = "class")
conf_i <- table(asuper$HeartDisease, pred_i)
conf_i #45 falsos positivos, 38 falsos negativos, 324 verdaderos negativos, 267 verdaderos positivos
acc_i <- sum(diag(conf_i)) / sum(conf_i)

print("La accuracy con el algoritmo ID3: ")
acc_i #Hemos obtenido un accuracy del 0.8768546 ~ 87,68%


print("La accuracy anterior con el modelo anterior (indice gini CART) es: ")
acc

```

Se calcula la predicción de los valores de la probabilidad que ha realizado cada algoritmo en sus modelos de árboles de decisión correspondientes (CART e ID3).
#La predicción de los valores de la probabilidad se refiere a cuanto de seguro está el algoritmo (predicción) de que ha clasificado correctamente o no.

```{r Predicción de los valores de la probabilidad de cada modelo (CART e ID3)}
# Predecimos valores de probabilidad utilizando el modelo anterior (índice gini CART)
all_probs <- predict(tree, asuper, type="prob")

# Muestra all_probs
summary(all_probs)

# Hay que seleccionar la columna numero 2, que marca los aciertos (1)
probs <- all_probs[,2]
probs

# tree_i es ID_3 porque se creó con ganancia de información como heurística
# Predecimos valores de probabilidad utilizando el modelo ID3
all_probs_i <- predict(tree_i, asuper, type="prob")
summary(all_probs_i)

#Hay que seleccionar la columna numero 2, que marca los aciertos (1)
probs_i <- all_probs_i[,2]
probs_i

```

Pasaremos a evaluar mediante la curva ROC y el área bajo la curva (valor AUC) cuanto de bien ha clasificado cada modelo elaborado por cada algoritmo (CART e ID3)

Podemos confirmar que entre el algoritmo CART e ID3, el algoritmo ID3 distingue mejor entre clases positivas y negativas, por lo que nos quedaríamos con el modelo que realiza este algoritmo.
```{r Evaluación de los modelos mediante curva ROC. Valor AUC o área bajo la curva}
#Evaluación algoritmo CART

# Prediction object:pred.
pred <- prediction(probs, asuper$HeartDisease)

# Performance object: perf
perf <- performance(pred, "tpr", "fpr")

# Plot de la curva ROC
plot(perf)

# Make a performance object: perf
perf_auc <- performance(pred, "auc")

# Impresión del valor AUC
print(perf_auc@y.values[[1]]) #89,35% de que el modelo pueda distinguir entre clase positiva y clase negativa



#Evaluación algoritmo ID3

# Prediction object: ID3
pred_i <- prediction(probs_i, asuper$HeartDisease)

# Performance object: perf_i
perf_i <- performance(pred_i, "tpr", "fpr")

# Plot de la curva ROC
plot(perf_i)

# Make a performance object: perf_i
perf_auc_i <- performance(pred_i, "auc")

# Impresión del valor AUC
print(perf_auc_i@y.values[[1]])#91,15% de que el modelo pueda distinguir entre clase positiva y clase negativa



#Dibujado de curvas ROC(perf, perf_i)
plot(perf)
plot(perf_i)


```
###########################################################################################################

#TODO: 
Algoritmo Knn (jodienda de tener que pasar atributos discretos como ChestPainType, RestingECG... a numéricos)
Practica 3: Clasificacion Ejercicio 3


#TODO
Algun algoritmo que se pueda sacar del paquete Caret de los cojones, ya que la profesora le dio importancia a eso 
y hace algunas cosas como cross validation y eso que lo ha mencionado 293423 veces en clase
Estuve probando con algunos metodos y daban todos problemas, pero hay muchos y alguno debería funcionar.

Para entender algo de lo que he hecho abajo, echale un vistazo antes a la practica 5: Paquete Caret



#########################################################################################################






####################################
#### LO DE ABAJO HABRA QUE CAMBIARLO. Sacado de la practica 5: paquete Caret  ###
####################################

La validación cruzada proporciona multiples estimaciones de error, en lugar de una estimación única como es el caso de test/train. Si todos las estimaciones son similares podemos estar seguros de la precisión del modelo, por el contrario si las estimaciones tienen resultados muy diferentes indican que el modelo no funciona de manera consistente y no es muy bueno. 

A continuación, mostraremos los diferentes tipos de validaciones cruzadas que aplicaremos para el entrenamiento de nuestro modelo de predicción con la ayuda de la función trainControl(). Además de calcular la probabilidad de la clasificación, calcularemos la probabilidad de las predicciones 

```{r Función trainControl: Diferentes tipos de validaciones cruzadas}
 
#?trainControl()  #Para saber más sobre la función trainControl()
myControl_clas1 <- trainControl(
                       method = "cv", #validacion cruzada
                       number = 10, #10 k folds
                       summaryFunction = twoClassSummary,
                       classProbs = TRUE, # Probabilidad de prediccion
                       savePredictions = TRUE,
                       verbose = FALSE
                      )
```

Función Train es la que entrena el modelo

```{r Funcion Train: entrenamiento y métodos de clasificación}
#?train()
#names(getModelInfo())
#Classification  methods: rocc, 


model_clas_glm <- train(HeartDisease~. ,#atributo a clasificar
                      asuper2, #Dataframe
                      method="glm",  #modelo de predicción
                      trControl=myControl_clas1 #Tipò de validación
                      )
model_class_glmnet <- train(HeartDisease~ ., asuper2, method = "glmnet", trControl = myControl_clas1) # aplica 3 valores de alpha y 3 valores de lambda
 
model_Class_glmnet


asuper2=as.factor(asuper2)

modelo1 <- train(HeartDisease~., data=asuper2, method="lm",trControl=myControl_clas1)
modelo1







```
